# -*- coding: utf-8 -*-
"""SpamDetector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cTljaaygdzRlATcYzppd-38I6em2LHVG

# Task
Analyze the "spam_ham_dataset.csv" dataset to build an email spam classifier using either Naive Bayes or SVM. Preprocess the data by removing stopwords, tokenizing, and applying TF-IDF vectorization. Split the data into training and testing sets, train the chosen model, and evaluate its performance using accuracy, precision, and recall. Finally, deploy the trained model using Gradio.

## Load the dataset

### Subtask:
Load the `spam_ham_dataset.csv` file into a pandas DataFrame.

**Reasoning**:
The instructions require loading the data, displaying the head, and printing the column names and data types. These steps can be combined into a single code block.
"""

import pandas as pd

df = pd.read_csv('spam_ham_dataset.csv')
display(df.head())
display(df.info())

"""## Preprocessing

### Subtask:
Clean and preprocess the email text data, including removing stopwords, tokenization, and applying TF-IDF vectorization.

**Reasoning**:
Import necessary libraries and download NLTK resources.
"""

import nltk
from sklearn.feature_extraction.text import TfidfVectorizer

nltk.download('punkt')
nltk.download('stopwords')

"""**Reasoning**:
Define a preprocessing function, apply it to the text column, initialize a TfidfVectorizer, fit and transform the cleaned text, and store the TF-IDF matrix.

**Reasoning**:
Download the missing 'punkt_tab' resource and re-run the code to preprocess the text and generate the TF-IDF matrix.
"""

import nltk

nltk.download('punkt_tab')

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer

stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()
    tokens = word_tokenize(text)
    cleaned_text = [word for word in tokens if word not in stop_words and word.isalnum()]
    return " ".join(cleaned_text)

df['cleaned_text'] = df['text'].apply(preprocess_text)

tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limiting features for simplicity
tfidf_matrix = tfidf_vectorizer.fit_transform(df['cleaned_text'])

display(tfidf_matrix.shape)

"""## Split the data

### Subtask:
Split the preprocessed data into training and testing sets.

**Reasoning**:
Split the preprocessed data (tfidf_matrix) into training and testing sets using train_test_split from sklearn.model_selection and display the shapes of the resulting sets.
"""

from sklearn.model_selection import train_test_split

X = tfidf_matrix
y = df['label_num']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""## Train a model

### Subtask:
Train a Naive Bayes or SVM model on the training data.

**Reasoning**:
Import the Naive Bayes model and train it on the training data.
"""

from sklearn.naive_bayes import MultinomialNB

model = MultinomialNB()
model.fit(X_train, y_train)

"""## Evaluate the model

### Subtask:
Evaluate the trained model's performance using accuracy, precision, and recall on the testing data.

**Reasoning**:
Calculate and print the accuracy, precision, and recall scores using the test data and the model's predictions.
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""## Deploy with gradio

### Subtask:
Create a Gradio interface to deploy the trained model for interactive spam classification.

**Reasoning**:
Import the gradio library, define the prediction function, create the gradio interface, and launch it to deploy the trained model.
"""

import gradio as gr

def classify_email(email_text):
    cleaned_text = preprocess_text(email_text)
    vectorized_text = tfidf_vectorizer.transform([cleaned_text])
    prediction = model.predict(vectorized_text)
    return "Spam" if prediction[0] == 1 else "Ham"

iface = gr.Interface(
    fn=classify_email,
    inputs=gr.Textbox(lines=10, label="Enter Email Text"),
    outputs=gr.Textbox(label="Classification Result"),
    title="Email Spam Classifier",
    description="Enter an email text to classify it as Spam or Ham."
)

iface.launch(share=True)

"""## Summary:

### Data Analysis Key Findings

*   The dataset contains 5171 email entries with columns for label, text, and numerical label.
*   Text data was successfully preprocessed by removing stopwords and tokenizing.
*   TF-IDF vectorization resulted in a feature matrix of shape (5171, 5000).
*   The data was split into training (3878 samples) and testing (1293 samples) sets, with a 75/25 split.
*   A Multinomial Naive Bayes model was trained on the training data.
*   The trained model achieved an accuracy of approximately 0.947, a precision of around 0.885, and a recall of about 0.931 on the test set.
*   A Gradio interface was successfully created and launched for interactive spam classification using the trained model.

### Insights or Next Steps

*   The Naive Bayes model demonstrates good performance in classifying spam emails based on the evaluation metrics.
*   The deployed Gradio interface provides a user-friendly way to interact with the trained model for real-time spam classification.

## README.md

# Email Spam Classifier

This repository contains code for an email spam classifier built using Python, pandas, scikit-learn, and Gradio. The classifier uses a Multinomial Naive Bayes model trained on the `spam_ham_dataset.csv` dataset.

## Project Structure

- `email_classifier.ipynb`: Jupyter Notebook containing the code for data loading, preprocessing, model training, evaluation, and Gradio deployment.
- `spam_ham_dataset.csv`: The dataset used for training and testing the model.

## Setup

1. Clone the repository:
"""

cd Email_Classifier

pip install pandas scikit-learn nltk gradio

import nltk
   nltk.download('punkt')
   nltk.download('stopwords')
   nltk.download('punkt_tab')

# This cell contains all the code from the notebook for easy copying.

import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, precision_score, recall_score
import gradio as gr

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')

# Load the dataset
df = pd.read_csv('spam_ham_dataset.csv')

# Preprocessing
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()
    tokens = word_tokenize(text)
    cleaned_text = [word for word in tokens if word not in stop_words and word.isalnum()]
    return " ".join(cleaned_text)

df['cleaned_text'] = df['text'].apply(preprocess_text)

tfidf_vectorizer = TfidfVectorizer(max_features=5000)
tfidf_matrix = tfidf_vectorizer.fit_transform(df['cleaned_text'])

# Split the data
X = tfidf_matrix
y = df['label_num']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Train a model
model = MultinomialNB()
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

# Deploy with Gradio
def classify_email(email_text):
    cleaned_text = preprocess_text(email_text)
    vectorized_text = tfidf_vectorizer.transform([cleaned_text])
    prediction = model.predict(vectorized_text)
    return "Spam" if prediction[0] == 1 else "Ham"

iface = gr.Interface(
    fn=classify_email,
    inputs=gr.Textbox(lines=10, label="Enter Email Text"),
    outputs=gr.Textbox(label="Classification Result"),
    title="Email Spam Classifier",
    description="Enter an email text to classify it as Spam or Ham."
)

iface.launch(share=True)